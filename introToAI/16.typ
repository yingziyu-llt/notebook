= 人工智能系统

== 流程
问题形式化：关注最重要最可行的问题

数据：高质量数据来源，隐私和安全

训练：模型越大，数据需求大，训练代价大

部署：复杂模型的实时推理差

维护：数据分布产生变化

== 数据搜集

数据来源：政府公开数据;科研数据;论文数据集;企业数据集;竞赛数据集...

可以分为3大类：论文数据；商业数据；人工收集数据

常见论文数据集：

MNIST:手写数字识别;
ImageNet：搜索引擎的百万图像；
KITTI:自动驾驶数据集/物体检测/物体分割；
Amazon Reviews:亚马逊用户评论/文本分类数据集

=== 爬虫入门

自学

要注意避免抓取敏感信息、版权的内容，遵循robot.txt规则。商用需要咨询律师。

=== 生成数据

- 使用GAN,stable diffusion等生成图片
- 模拟器生成
- 数据增强（语料可以做translate back，用chatbot生成对话等等）

== 数据标注

流程：收集数据->有合适的标签直接做分类->标签数量不足做半监督学习->预算充足做众包(crowdsoursing)->只有弱标签可以做弱监督学习

众包的时候，为了增加数据质量，多人标记一张图片，投票后决定；一段时间后利用算法算出来置信度等，从而加权投票。

=== 半监督学习

先在标注好的训练数据上训一个还不错的模型，在此之后在无标签的训练样本上跑。跑出的结果中置信度高的把预测值作为伪标签(seudo label)，放回训练数据，重新计算。

==== 缺点
训练成本高，存在误差累计(accumulate error)问题。

==== 和众包结合
把置信度差的扔给众包处理

把最有趣的数据标记，有人的参与(human in loop)

找困难的例子有两种方法：uncernty/委员会查询

自监督学习是无监督学习！

对比学习：将正样本之间的特征尽可能近，负样本的特征尽可能的远。
